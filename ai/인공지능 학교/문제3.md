# 문제 정리
### AI (6 ~ 10)
1. 다음 중 옳지 않은 것을 고르시오.
> 1. 과거의 인공지능, 머신러닝 기반의 시스템은 주로 확률과 관련이 있었다.   
> 2. 연속형 데이터는 키, 나이, 가격 등이 있다.   
> 3. 범주형 데이터가 속한 기술 통계학은 가설 설립 및 검정을 통해 각 데이터 간의 상관관계를 분석한다. [정답]   
> 4. 추론 통계학에서 모집단을 전국민이라 한다면 표본은 무작위 선정한 시민이라 할 수 있다.
2. [A], [B], [C], [D]에 들어갈 단어로 바르게 짝지어 진 것을 고르시오.
```
[A]은/는 평균과의 거리를 제곱한 값의 평균이다.

[B]은/는 데이터의 변량이다. [B]를 통해 데이터가 얼마나 흩어져 있는지 알 수 있다.

[C]은/는 데이터의 무게중심이 어디인지 나타내는 값으로 특이값의 영향을 크게 받는다.

[D]은/는 값들을 순서대로 나열했을 때 순서상 중앙에 위치하는 값이다.

정규분포에서 최빈값, [C], [D]은/는 같은 선상에 위치한다.
```
> 1. [A] : 표준편차, [B] : 분산, [C] : 평균, [D] : 중앙값   
> 2. [A] : 분산, [B] : 산포, [C] : 중앙값, [D] : 평균   
> 3. [A] : 분산, [B] : 산포, [C] : 평균, [D] : 중앙값 [정답]   
> 4. [A] : 표준편차, [B] : 분산, [C] : 중앙값, [D] : 평균
3. 다음 설명이 맞으면 O, 틀리면 X를 고르시오.
IQR(InterQuartile Range)는 Q4에서 Q1을 뺀 값이다.
> 1. O   
> 2. X [정답]
4. [빈칸]에 들어갈 단어로 가장 알맞은 것을 고르시오. 
```
경사하강법은 [빈칸]의 값을 최소화시키기 위해 마치 경사를 내려가듯 최솟값을 찾는 기법
```
> 1. 목적함수 [정답]   
> 2. 학습률   
> 3. 절편   
> 4. 상수
5. 다음 수식에 대한 설명으로 옳지 않은 것을 고르시오.
> 1. 위 수식의 목적은 값이 가장 커지는 파라미터들을 찾는 것이다. [정답]   
> 2. 제곱을 시켜줌으로써 오차 값이 클 때는 더 크게 인식되는 효과가 있다.   
> 3. 실제 결괏값과 예측 결괏값의 차이에서 음수가 발생하지 않도록 하기 위해 제곱을 해준다.   
> 4. 1/2를 하는 이유는 결과로 나온 식을 간단한 모양으로 만들기 위함이다.
6. 다음 중 옳지 않은 것을 고르시오.
> 1. 머신러닝의 핵심은 과거의 관측을 기반으로 새로운 샘플의 결괏값을 예측하는 것이다.
> 2. 상수는 미분해도 변화가 없다. [정답]   
> 3. 학습률을 너무 작게 잡으면 최솟값에 수렴하기까지 많은 시간이 걸린다.   
> 4. 학습률에는 정답이 없다.
7. '편미분'에 대한 설명으로 옳지 않은 것을 고르시오. 
> 1. 2개의 매개변수가 있다면 편미분을 해야 한다.   
> 2. 다변수 함수를 미분할 때 미분할 변수를 상수로 취급하는 계산을 편미분이라 한다. [정답]   
> 3. 편미분을 진행할 때는 미분 연산자에 있는 기호가 델 연산자로 바뀐다.   
> 4. 시그마 기호와 미분 연산자의 위치를 바꿀 수 있다.
8. h(x, y) = 3x²y+y²-70y-2 를 x로 편미분한 값을 고르시오.
> 1. 2y   
> 2. 70   
> 3. 3x²   
> 4. 6xy [정답]
9.  [빈칸]에 들어갈 단어로 가장 알맞은 것을 고르시오.
```
머신러닝에서 학습 데이터를 과하게 학습하여 학습 데이터에서는 정확도가 높지만
실제 데이터에서는 오차가 발생하는 것을 [빈칸]이라고 한다.
```
> 1. 갱신식   
> 2. 과적합 [과적합]   
> 3. 다항식 회귀   
> 4. 함수의 치환
10. 다음 설명이 맞으면 O, 틀리면 X를 고르시오.
```
머신러닝에서 문제를 해결할 때 여러 알고리즘을 비교하여 사용하기보다는
일반적으로 하나의 알고리즘으로 접근한다.
```
> 1. O   
> 2. X [정답]
11.  [A], [B]에 들어갈 단어로 바르게 짝지어 진 것을 고르시오.
```
[A]은/는 분류를 확률로 생각하는 방식으로 어느 클래스에 분류되는지 구하는 것이다.
그리고 이를 구하는 함수가 [B]이다.
[B]의 그래프 모양은 S자 형태를 띠며 어떠한 입력값이 들어와도 0~1사이의 값을 반환한다.
```
> 1. [A] : 퍼셉트론, [B] : 로지스틱 시그모이드 함수   
> 2. [A] : 로지스틱 회귀, [B] : 지수함수   
> 3. [A] : 로지스틱 회귀, [B] : 로지스틱 시그모이드 함수   
> 4. [A] : 퍼셉트론, [B] : 지수함수 [정답]
12. 서포트 벡터 머신(Support Vector Machine, SVM)의 단점으로 옳은 것을 고르시오.
> 1. 상당한 컴퓨팅 파워가 필요하다. [정답]   
> 2. 계산 비용이 적다.   
> 3. 정확도가 낮다.   
> 4. 선형 분리 불가능 문제를 해결할 수 없다.
13. [빈칸]에 공통으로 들어갈 단어로 가장 알맞은 것을 고르시오. 
```
결정 트리 학습(Decision Tree)은 [빈칸]이 최대가 되는 특성으로 데이터를 나눈다.
```
> 1. 지니 불순도   
> 2. 엔트로피   
> 3. 정보 이득 [정답]   
> 4. 분류 오차
14. 불순도 지표에 대한 설명으로 옳지 않은 것을 고르시오.
> 1. 지니 불순도를 사용할 때는 가지치기 수준을 바꿔가며 실험하는 것이 좋다.   
> 2. 한 노드의 모든 데이터가 같은 클래스라면 엔트로피는 최대 1이다. [정답]   
> 3. 분류 오차에서 두 클래스가 같은 비율일 때 최댓값은 0.5이다.   
> 4.지니 불순도가 엔트로피와 분류 오차의 중간 정도에 위치한다.
15. 
3. K-근접 이웃(K-Nearest Neighber, KNN)의 특징으로 옳은 것을 고르시오.
> 1. 충분한 학습 과정을 진행한 후 사용할 수 있다.   
> 2. 데이터 저장 공간이 불필요하다.   
> 3. 차원의 저주를 피하기 위한 차원 축소 기법을 사용하지 않는다.   
> 4. 과적합과 과소 적합 사이에 있는 적절한 k값을 설정해야 한다. [정답]