# 문제 정리
### AI (11 ~ 17)
1. K-Means 4단계 알고리즘을 순서대로 나타낸 것을 고르시오.
```
[A] 무작위로 k개의 센트로이드를 초기 클러스터 중심으로 선택한다.
[B] 클러스터 할당이 변하지 않거나,
사용자가 지정한 허용오차나 최대 반복 횟수에 도달할 때까지 2단계와 3단계를 반복한다.
[C] 각 데이터를 가장 가까운 센트로이드에 할당한다.
[D] 할당된 샘플들의 중심으로 센트로이드를 이동시킨다.
```
> 1. [A] - [B] - [C] - [D]   
> 2. [A] - [C] - [D] - [B] [정답]   
> 3. [C] - [D] - [A] - [B]   
> 4. [C] - [A] - [D] - [B]
2. 다음 중 K-Means의 특징으로 옳지 않은 것을 고르시오. 
> 1. 매우 쉬운 구현성을 가지고 있지만 계산 효율성이 낮다. [정답]   
> 2. 프로토타입 기반 군집에 속한다.   
> 3. 클러스터 내의 제곱 오차합(SSE)을 반복적으로 최소화하여 최적화 시킨다.   
> 4. K-Means의 초기 센트로이드 무작위성을 보완하기 위해 K-Means++가 등장했다.
3. [빈칸]에 대한 설명으로 옳지 않은 것을 고르시오. 
```
[빈칸]은/는 클러스터링 품질을 평가하는 방법 중 하나로,
클러스터 내 데이터들이 얼마나 조밀하게 모여있는지 측정하는 그래프 도구이다.
클러스터 응집력과 분리도를 구한 뒤 그 차이를 둘 중 큰 값으로 나눠 계산한다.
```
> 1. 응집력과 분리도가 같다면 계산 결과는 0이다.   
> 2. 응집력을 통해 클러스터 내 다른 샘플과 얼마나 비슷한지 알 수 있다.   
> 3. 최적인 클러스터 개수 k를 추정하여 왜곡값(SSE)이 빠르게 증가하는 지점의 k값을 찾는다. [정답]   
> 4. 응집력이 작을수록 클러스터 내 다른 데이터들과 비슷하다는 뜻이다.
4. 다음 중 계층 군집에 대한 설명으로 옳지 않은 것을 고르시오. 
> 1. 계층 군집 알고리즘의 장점은 덴드로그램을 그릴 수 있다는 것이다.   
> 2. 계층 군집은 누군가에게 군집 결과를 설명하기에 적합하다.   
> 3. 계층 군집을 형성하는 방법에는 병합 계층 군집과 분할 계층 군집으로 나누어진다.   
> 4. 계층적 알고리즘은 클러스터의 수를 미리 지정해 주어야 한다. [정답]
5. 병합 계층 군집을 이루는 알고리즘 중 클러스터 쌍에서 가장 가까운 데이터 간의 거리를 계산하여 거리의 값이 가장 작은 두 클러스터를 하나로 합치는 연결 방식(알고리즘)은 무엇인지 고르시오. 
> 1. 단일 연결 [정답]   
> 2. 완전 연결   
> 3. 평균 연결   
> 4. 와드 연결
6. 다음 중 밀집도 기반 군집 알고리즘에 대한 설명으로 옳지 않은 것을 고르시오.
> 1. 원형 클러스터를 가정하지 않는다.   
> 2. 데이터가 조밀하게 모인 지역에 클러스터 레이블을 할당한다.   
> 3. 밀집도란 특정 반경 안에 있는 샘플의 거리로 정의한다. [정답]   
> 4. 데이터의 특성이 늘어남에 따라 차원의 저주 문제가 발생하게 된다.
7. 다음 중 딥러닝에 대한 설명으로 옳지 않은 것을 고르시오.
> 1. 계층 구조로 구성되며 입력층과 출력층 사이에 하나 이상의 은닉층을 가지고 있는 심층 신경망이다.   
> 2. 인공 신경망은 심층 신경망의 일종이다. [정답]   
> 3. 인공 신경망은 인간의 뇌 구조를 모방하여 모델링한 수학적 모델이다.   
> 4. 인간의 뇌를 형성하는 뉴런의 집합체를 수학 모델로 표현한 것이 인공 신경망이다.
8. 다음 중 인간의 뇌 구조에 대한 설명으로 옳지 않은 것을 고르시오.
> 1. 뉴런의 입력과 출력은 하나이다. [정답]   
> 2. 여러 신경세포로부터 전달되어 온 신호들이 합산되어 출력된다.   
> 3. 합산된 값이 설정값 이상이면 출력 신호가 생기고, 이하면 출력 신호가 생기지 않는다.   
> 4. 시냅스는 다수의 뉴런을 연결해 주는 역할을 담당하고 있다.
9. 다음 중 딥러닝에 대한 설명으로 옳지 않은 것을 고르시오.
> 1. 충분한 하드웨어와 그래픽 처리 장치는 딥러닝의 발전에 큰 영향을 주었다.   
> 2. CNN 기반의 딥러닝은 일반 그림을 유명 화가의 화풍에 맞게 그려주는 기술로 발전되었다.   
> 3. 음성 혹은 글자와 관련된 부분은 순환 신경망보다는 CNN이 활용된다. [정답]   
> 4. 이미지 인식에 주로 CNN 기반 딥러닝이 사용된다.
10.  다음 중 맥컬록-피츠 뉴런(MCP)에 대한 설명으로 옳지 않은 것을 고르시오.
> 1. 1943년 워랜 맥컬록과 월터 피츠는 처음으로 간소화된 뇌의 뉴런 개념을 발표했다.   
> 2. 맥컬록과 피츠는 신경세포를 십진 출력을 내는 논리회로로 표현했다. [정답]   
> 3. 프랭크 로젠 블렛은 MCP 뉴런 모델을 기반으로 퍼셉트론 학습 개념을 발표한다.   
> 4. 퍼셉트론 규칙에서 프랭크 로젠 블렛은 자동으로 최적의 가중치를 학습하는 알고리즘을 제안한다.
11. 다음 중 뉴런에 대한 설명으로 옳지 않은 것을 고르시오.
> 1. 하나의 뉴런에는 가중치와 활성화 함수가 있다.   
> 2. 활성화 함수는 뉴런의 출력값을 정하는 함수이다.   
> 3. 입력에 가중치를 더한 뒤, 활성화 함수를 취하면 출력값을 얻을 수 있다. [정답]   
> 4. 뉴런에서 학습할 때 변하는 것은 가중치이다.
12. 다음 중 연산에 대한 설명으로 옳지 않은 것을 고르시오. 
> 1. AND 연산의 경우 모두 참인 경우만 참을 출력하고 나머지 경우에 대해서는 거짓을 출력한다.   
> 2. OR 연산의 경우 하나라도 참이면 참을 출력하고 나머지 경우에 대해서는 거짓을 출력한다.
> 3. XOR 연산의 경우 하나라도 거짓이면 거짓을 출력하고 나머지 경우에 대해서는 참을 출력한다. [정답]   
> 4. 다층 퍼셉트론으로 AND, OR, XOR 연산 문제를 모두 해결할 수 있다.
13. 다음 중 신경망에 대한 설명으로 옳지 않은 것을 고르시오.
> 1. 신경망의 목적은 손실 함수가 최솟값일 때의 파라미터를 찾아 올바른 학습 결과를 내는 것이다.   
> 2. 신경망의 목적은 회귀분석이나 로지스틱 회귀와 기본 개념이 같다.
> 3. 신경망보다 회귀분석에서 사용하는 파라미터의 개수가 더 많다. [정답]   
> 4. 신경망의 가중치를 효율적으로 찾는 방법으로 역전파가 있다.
14. 다음 중 출력값과 지도 데이터 사이에서 생기는 '오차'를 이용해 출력층에서 입력층 쪽으로 가중치를 조정하는 방법은 무엇인지 고르시오.
> 1. 회귀 분석   
> 2. 로지스틱 회귀   
> 3. 순전파   
> 4. 역전파 [정답]
15. 다음 설명 중 옳지 않은 것을 고르시오.
> 1. 손실 함수는 출력값과 지도 데이터 사이의 오차이다.   
> 2. 역전파는 손실 함수가 최솟값일 때의 가중치로 원래의 가중치를 조정한다.   
> 3. 특정 입력값에서 손실 함수 최솟값은 크게 의미가 없다.   
> 4. 경사하강법에서 기울기 값이 0이면 반드시 손실 함숫값이 최솟값이 된다. [정답]
16. [빈칸]에 들어갈 알맞은 활성화 함수를 고르시오. 
```
역전파 기법은 기울기 소멸 문제로 신경망이 깊어지면 깊어질수록
오차의 기울기가 점차 작아지며 기울기가 소멸되는 문제가 발생하지만
[빈칸] 활성화 함수를 활용하여 어느 정도 해결할 수 있었다.
이 활성화 함수는 입력이 음수일 때는 0을 출력하지만 양수일 때는 양수 값을 그대로 출력한다.
```
> 1. Sigmoid   
> 2. Softmax   
> 3. ReLU [정답]   
> 4. ELU
17. 다음 중 강화학습에 대한 설명으로 옳지 않은 것을 고르시오. 
> 1. 에이전트가 환경과 상호작용하며 보상을 최대화하는 방향으로 학습을 진행한다.   
> 2. 다양한 시행착오를 통해 학습이 가능하다.   
> 3. 지도 학습처럼 정답이 있으며, 비지도 학습처럼 데이터를 기반으로 학습한다. [정답]   
> 4. 비교적 명확한 보상을 설정할 수 있는 문제 해결에 사용되고 있다.
18. 다음 중 MDP의 구성요소와 그 역할이 알맞게 짝 지어지지 않은 것을 고르시오.
> 1. 환경 : 의사결정을 하는 주체 [정답]   
> 2. 상태 : 에이전트가 의사 결정을 하기 위한 관측 값, 행동, 보상 등을 가공한 것   
> 3. 행동 : 에이전트가 의사결정을 통해 취할 수 있는 것   
> 4. 보상 함수 : 에이전트가 특정 상태에서 특정 행동을 했을 때 주어지는 보상의 기댓값을 정의하는 함수
19. [빈칸]에 들어갈 적절한 용어는 무엇인지 고르시오.
```
[빈칸]은 초기 상태에서 에이전트가 미래에 받을 보상을 현재 가치로 환산하여 효율적인 판단을 할 수 있도록 하는 값으로 0과 1사이의 값으로 구성된다.
```
> 1. 행동률   
> 2. 학습률   
> 3. 감가율 [정답]   
> 4. 관측률
20. 다음 중 강화학습에서 에이전트가 다양한 경험을 할 수 있도록 에이전트의 행동을 결정하는 기법을 무엇이라고 하는지 고르시오.
> 1. 이용   
> 2. 탐험 [정답]   
> 3. 활용   
> 4. 탐욕
21. 다음 중 강화학습에 대한 설명으로 옳지 않은 것을 고르시오.
> 1. 주요 목적은 에이전트가 많은 보상을 받기 위해 최적의 정책을 학습하는 것이다.   
> 2. 단 한 번의 행동에 대해 최대의 보상을 원한다면 활용이 바람직하다.   
> 3. 무작위 탐색 방법을 사용하여 최대한 다양한 경험만을 추구하는 것이 가장 좋은 방향이다. [정답]   
> 4. 장기적으로 보상의 총합을 키우기 위해서는 탐험이 필요하다.
22. 다음 중 강화학습에 대한 설명으로 옳지 않은 것을 고르시오.
> 1. 하나의 행동을 선택할 때, 활용과 탐험을 동시에 할 수 없기 때문에 이것은 종종 활용과 탐험의 딜레마 혹은 갈등으로 불리게 된다.   
> 2. 활용과 탐험의 적절한 분배에 대한 필요성은 강화학습에서만 나타나는 독특한 어려움이다.   
> 3. 탐험의 기본적인 방법 중 하나는 탐욕적 방법이 있다. [정답]   
> 4. 탐험과 활용을 적절히 분배하는 것이 중요하다.