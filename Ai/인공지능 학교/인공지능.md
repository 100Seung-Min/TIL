# 통계학
---
### 1. 기술 통계학
> 연속형 
>> 키/나이/가격 -> 평균, 표준편차
> 범주형 데이터
>> 이름/종족/성별 -> 빈도 백분율
### 2. 추론 통계학
> 작은 단서 ->가설설립,검정 -> 문제해결
>> 가설검정   
>> 수치로 되어 있는 특징들을 계산   
>> 각 데이터 간의 상관관계를 분석
---
### 통계모델링
> 데이터에 통계를 적용하여 변수의 유의성을 분석함으로써 방대한 양의 데이터에 숨겨진 특징을 찾아내는 것을 의미한다.
> 확률분포
>> 종모양인 정규분포가 대부분이다
>> 최빈값은 볼록한 부분이다
### 목적함수
> 오차를 알려주는 식
> 각각의 데이터마다 결과와 예측값의 오차를 제곱해서 더한후 2분의 1을 곱한다.
### 경사하강법
> 목적함수의 값을 최소화한다
### 편미분
> 두개의 변수를 가진 함수를 미분하는 것   
> 하나의 변수를 제외한 변수는 상수 취급
### 합성함수
> 함수가 여러개 조합된 것
### 다항식 회귀
> 다항식의 차수를 늘리는 것
### 퍼셉트론
> 여러개의 입력을 받아 각각의 값에 가중치를 곱한 후, 모두 더한 것이 출력되는 모델
### 로지스틱 회귀
> 분류를 확률로 생각하는 방식   
> 어느 클래스에 분류 되는지 구하는 것   
> 구할 때는 로지스틱시그모이드함수가 필요
### 서포트 벡터머신 (SVM)
> 결정경계를 정한후 마진을 줘서 서포트 벡터를 구한다.   
> 선형분리 불가능 문제도 해결가능하다.   
### 결정 트리 학습
> 훈련 데이터에 있는 특성을 기반으로 새로운 샘플의 클레스 레이블을 추정할 수 있도록, 질문을 학습하는 것   
> 범주형 변수, 실수형 변수 모두 가능   
> 많은 질문은 과적합이 되므로 가지치기를 해야한다   
### 불순도지표
> 지니불순도
>> 잘못 분류될 확률을 확률을 최소화 하기 위한 기준
>> 가지치기 수준을 바꿔가며 실험을 권장한다
> 엔트로피
>> 특정 노드 t에서 클래스 i에 속한 데이터 비율   
>> 모든 데이터가 같은 클래스면 0, 분포가 균등하면 최대 1
> 분류 오차
>> 두 클래스가 같은 비율이면 최대 0.5   
>> 노드의 클래스 확률 변화에 둔감
### K 최근접 이웃(KNN)
> 학습과정이 없는 알고리즘   
> 매번 학습을 진행해야한다   
> 유클리디안 거리 측정방식을 통해 거리를 구한다   
> 우리가 설정한 값만큼 최근접 이웃을 찾는다   
> 미지의 데이터 클레스 레이블을 할당한다
### 군집분석 -> 비지도 학습
### k-평균
> 프로토타입 기반 군집   
>> 데이터 포인트에서 랜덤하게 k개의 센트로이드를 초기 클러스터 중심으로 선택   
>> 각 데이터를 가장 가까운 센트로이드에 할당   
>> 할당된 샘플들을 중심으로 센트로이드를 이동   
>> 클러스터 할당이 변하지 않거나, 사용자가 지정한 허용오차나, 최대 반복횟수에 도달할 때 까지 두번째와 세번째 과정을 반복   
> 클러스터 내의 제곱 오차합을 반복적으로 최소화하여 최적화한다.
### 사이킷런
### 계층군집
> 덴드로그램을 그릴 수 있다.   
> 의미있는 분류 체계   
> 병합 계층 군집
>> 클러스터를 병합해나가 하나의 데이터가 될 때까지 반복
> 분할 계층 군집
>> 전체 데이터를 포함해 , 클러스터를 계속해서 나누는 것
> 단일 연결
>> 가까운 클러스터를 합친다
> 완전 연결
>> 가장 먼 클러스터를 합친다
> 평균 연결
>> 거리의 평균이 가장 적은 것을 합친다
> 와드 연결
>> 제곱 오차합이 가장 작게 증가하는 클러스터를 합친다
---
### 통계용어
> 1. 산포
>> 데이터가 얼마나 중심으로 모이지 않고 흩어져 있는지   
>> 이를 구하기 위한 것이 분산이다
> 2. 분산
>> 평균과의 거리를 제곱한 값의 평균
> 3. 표준편차
>> 분산의 제곱근
> 4. 사분위수
>> 데이터 구성을 전체적으로 살펴보고자 할 때 사용   
>> 데이터의 이상치 탐색과 중심위치 및 분포를 빠르게 파악할 수 있다.   
>> 가장 작은 수부터 정렬 후 25%의 간격의 숫자들을 의미한다.
> 5. 미분
>> 어떤 구간에서의 그래프의 기울기를 구한다   
>> 이것을 반복해 간격을 점차 좁히며 기울기를 구하는 것
> 6. 도함수
>> 미분후에 나온 함수
> 7. 학습률
>> 높이 잡으면 멀어지게 된다(발산현상관측)   
>> 낮게 잡으면 시간이 오래 걸린다(수렴속도지연)
---
### 딥러닝
> 인공 신경망
>> 인간의 뇌를 수학모델로 표현한 것
> 뉴런 (연결하면 시냅스)
>> 입력 -> 수상돌기   
>> 입력합산 지점 -> 세포체(노드)   
>> 출력 -> 축삭   
> 심층 신경망
### CNN(합성곱 신경망)
### RNN(순환 신경망)
> LSTM으로 발전   
> GRU로 발전